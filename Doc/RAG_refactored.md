# 海口智能旅游助手 RAG 系统设计文档（重构版）

> 说明：本文件为对现有 `RAG.md` 的结构化精简与重组版本。原文件保留用于溯源。本版聚焦“为什么 / 做什么 / 怎么做 / 如何运维 / 如何扩展”。详细底层代码与长篇日志说明移动到附录或保留于旧文档。

---
## 目录
1. 概述
2. 业务需求分析
3. 总体架构设计  
   3.1 系统架构  
   3.2 核心技术栈  
   3.3 模块职责一览  
4. 核心机制  
   4.1 文档处理与分块策略  
   4.2 向量索引与缓存体系  
   4.3 嵌入模型按需加载与智能启动  
   4.4 RAG 查询流程  
   4.5 工具调用编排（MCP + 文档）  
5. 安全与合规  
    5.1 认证与权限  
    5.2 文件与输入安全  
    5.3 错误与日志管理  
6. 运维与部署  
    6.1 环境与配置  
    6.2 部署形态  
    6.3 监控与故障排查  
7. 使用指南  
    7.1 管理员操作流程  
    7.2 用户使用路径  
    7.3 常见问题 FAQ  
8. API 参考（精简版）  
9. 技术特性总结  
10. WebPage‑Flask 集成说明  
11. 附录  
   A. 关键代码片段  
   B. 数据与缓存结构示例  
   C. 模型与参数调优要点  
12. 与旧版差异与迁移指引

---
## 1. 概述
海口智能旅游助手通过 RAG（检索增强生成）+ 实时工具（MCP）融合，为旅游问答提供：
- 本地化细粒度知识（餐厅、免税购物政策、拍照点）
- 实时数据（天气、POI、距离）
- 低冷启动成本（按需加载 + 缓存复用）

核心目标：在 3–5 秒启动、<1 秒增量查询预处理、≈500ms 检索阶段内，为用户输出可追溯、上下文增强的回答。

---
## 2. 业务需求分析
| 需求维度 | 说明 | 响应策略 |
|----------|------|----------|
| 时效性 | 天气 / 活动 / 政策可能更新 | 实时工具优先 + 文档增量更新机制 |
| 本地化 | 小众地点/免税政策官方渠道不集中 | 自建结构化 + 半结构化知识库 |
| 个性化 | 家庭 / 拍照 / 商务旅客差异 | 语义检索 + 分类标签（亲子/免税/打卡） |
| 成本效率 | 避免大模型长上下文反复推理 | 先检索后生成，控制 prompt 体积 |
| 可运维 | 管理员需快速追踪状态 | 缓存状态接口 + 日志分级 |

场景示例（精简）：
- 拍照打卡：检索“海口 + 日落 + 机位推荐” → RAG 文档优先
- 免税购物：政策 + 限购 + 商品分类 → 文档+策略摘要块召回
- 特色餐饮：多维标签（菜系 / 人均 / 氛围）→ JSON 结构化索引支持字段过滤

---
## 3. 总体架构设计
### 3.1 系统架构（逻辑流）
前端（对话/管理） → Flask API → 工具编排层 → (MCP 工具 / RAG 引擎) → 向量缓存 + 模型 → LLM 生成层

### 3.2 核心技术栈
Flask / gevent；SentenceTransformers(Qwen Embedding)；豆包 API；pandas / PyPDF2 / python-docx；本地 pickle + 内存热缓存；前端原生 + 部分异步 fetch。

### 3.3 模块职责一览
| 模块 | 职责 | 关键点 |
|------|------|--------|
| 文档上传与管理 | 存储、描述、索引触发 | 文件白名单 + MD5 内容哈希 |
| 分块与嵌入 | 文本切分 + 向量化 | 语义/长度双策略 + overlap |
| 向量缓存 | 读取/热重载 | mtime 对比 + 内存单例 |
| RAG 查询 | 相似度检索 + 上下文拼接 | 阈值过滤 + TopK 控制 |
| 工具编排 | 决策使用 RAG / MCP | 意图分类 + 步骤循环 |
| 按需加载 | 模型延迟加载 | 有缓存→异步 / 无缓存→跳过 |
| 安全层 | 认证、文件与权限 | Session + 路径校验 |
| 运维监控 | 状态检查 & 日志 | 缓存 / 模型 / API 成功率 |

---
## 4. 核心机制
### 4.1 文档处理与分块策略
- 支持：PDF / DOCX / XLSX / JSON / MD / TXT（如已移除 TXT 支持，则与前端保持一致）
- 分块模式：
  - 语义分句（保语义完整）
  - 定长字符（回退策略，标点优先断点）
- 参数：`max_chars=500`，`overlap=50`
- 元数据：`source|name|chunk_id|tags|uploaded_at`

### 4.2 向量索引与缓存体系
双层：
1. 模型单例缓存（内存）
2. 向量数据缓存（文件 + 内存热数据 + 热重载）

缓存文件结构（示例）：
```python
cache = {
  'hash': '<docs_md5>',
  'texts': [...],
  'embeddings': np.ndarray(shape=(N, D)),
  'meta': [{ 'source': 'xxx', 'tags': ['免税','政策'] }...],
  '_mtime': 1736500000.123
}
```
更新策略：
- 重新上传/删除 → 重新计算 → 写临时文件 → 原子 rename → 清空内存缓存 → 下次查询热加载
- 未变更 → 跳过重算（哈希比对）

### 4.3 嵌入模型按需加载与智能启动
策略矩阵：
| 场景 | 有向量缓存 | 动作 | 模型状态 | 启动耗时 |
|------|------------|------|----------|----------|
| 首次冷启动 | 否 | 跳过加载 | 未加载 | 3–5s |
| 正常启动 | 是 | 后台线程异步加载 | 加载中→就绪 | 3–5s |
| 生成索引后 | - | 同步已加载 | 已就绪 | - |

核心函数（概念示例）：
```python
def get_embedding_model():
    if model is None:
        model = SentenceTransformer(NAME, device='cpu')
    return model
```

### 4.4 RAG 查询流程
1. 解析用户问题 → 关键词精简 / 去噪
2. 加载缓存（内存命中或文件热载）
3. 向量化查询 → 计算相似度 → TopK + 阈值过滤
4. 构造 Prompt：加入最相关 3–5 块（控制 token）
5. LLM 生成 → 附带来源标注
6. 失败处理：无相关 → 建议重述 or 指向管理员

### 4.5 工具调用编排（MCP + 文档）
策略：实时数据优先 MCP；静态知识优先 RAG；复合任务分阶段（例如：先政策 → 再地点搜索）。
循环控制：工具调用历史 → 信息充分性判定 → 继续 / 终止 → 最终汇总回答。

---
## 5. 安全与合规
### 5.1 认证与权限
- 环境变量配置管理员账户；Session 控制后台访问
- 未来可扩展 Token / RBAC

### 5.2 文件与输入安全
- 白名单扩展名
- 限制大小（16MB）
- 路径规范化防遍历
- 描述字段长度/字符过滤

### 5.3 错误与日志管理
- 统一响应格式：`status|msg|details`
- 分级日志：控制台 INFO / 文件 DEBUG
- 关键路径：上传、索引、查询、工具调用

---
## 6. 运维与部署
### 6.1 环境与配置（示例）
```
ARK_API_KEY=xxx
ADMIN_USERNAME=admin
ADMIN_PASSWORD=***
SECRET_KEY=***
```
### 6.2 部署形态
- 本地开发：`python app.py`
- Docker：多阶段构建 / 只保留运行层
- 生产：Gunicorn + gevent / 反向代理（Nginx）

### 6.3 监控与故障排查
| 症状 | 排查 | 可能原因 |
|------|------|----------|
| RAG 不可用 | 缓存文件是否存在 | 索引未生成 |
| 查询慢 | 模型是否已加载 | 首次加载中 |
| 上传失败 | 日志 413/415 | 大小或类型限制 |

---
## 7. 使用指南
### 7.1 管理员操作流程
1. 登录后台 → 上传文档 → 生成索引 → 监控日志
2. 更新文档 → 重新生成索引（自动刷新缓存）

### 7.2 用户使用路径
1. 对话输入问题
2. 系统自动判定是否调用工具或检索
3. 回答含来源标注（若为 RAG）

### 7.3 常见问题 FAQ（示例）
- 首次索引慢？模型初始化+向量计算正常现象
- 没有结果？尝试缩短或聚焦关键词
- 政策不更新？需管理员重新上传最新文档

---
## 8. API 参考（精简版）
| 功能 | 方法 | 路径 | 说明 |
|------|------|------|------|
| 对话 | POST | /api/chat | 多轮对话+工具编排 |
| 上传 | POST | /upload 或 /api/upload | 上传单个文档 |
| 文件列表 | GET | /api/files | 返回已上传文档 |
| 生成索引 | POST | /api/generate_index | 触发重建向量缓存 |
| 索引状态 | GET | /api/index_status | 是否存在缓存 |
| RAG 测试 | POST | /api/rag_query | 单次检索试验 |

统一响应：
```json
{"status": "success|error", "msg": "...", "data": {...}}
```

---
## 9. 技术特性总结
- 智能启动：缓存驱动的按需加载
- 双层缓存：模型单例 + 向量热重载
- 工具融合：RAG + MCP 实时工具协同
- 扩展友好：新增工具/模型无需改核心管线
- 运维可视：状态接口 + 统一日志格式

---
## 10. WebPage‑Flask 集成说明
- 模板：`index.html`（对话）、`doc.html`（管理）
- 前端调用：`fetch('/api/...')` 简单 REST 风格
- 会话控制：本地存储 + 服务端 Session（可改JWT）

---
## 11. 附录
### A. 关键代码片段（示意）
```python
# 模型获取
_embedding_model = None

def get_embedding_model():
    global _embedding_model
    if _embedding_model is None:
        _embedding_model = SentenceTransformer(MODEL, device='cpu')
    return _embedding_model
```
```python
# 缓存加载
_embedding_cache = None
_cache_mtime = None

def load_embedding_cache(path):
    global _embedding_cache, _cache_mtime
    mtime = os.path.getmtime(path)
    if _embedding_cache and _cache_mtime == mtime:
        return _embedding_cache
    with open(path,'rb') as f:
        _embedding_cache = pickle.load(f)
    _cache_mtime = mtime
    return _embedding_cache
```

### B. 数据与缓存结构示例
```json
{
  "hash": "b93af...",
  "texts": ["块1文本", "块2文本"],
  "embeddings_shape": [240, 1024],
  "meta_sample": {"source": "政策.md", "tags": ["免税"]}
}
```

### C. 模型与参数调优要点
| 维度 | 当前值 | 可调方向 |
|------|--------|----------|
| embedding 模型 | Qwen3 0.6B | 更大模型提升召回精度 |
| 分块大小 | 500 chars | 动态调优基于平均句长 |
| TopK | 5 | 自适应基于相似度分布 |
| 阈值 | 0.3 | 调整至 0.25/0.35 观察噪音比 |

---
## 12. 与旧版差异与迁移指引
| 旧版章节 | 现位置 | 处理说明 |
|----------|--------|----------|
| 嵌入模型按需加载系统 | 4.3 | 精简述语 + 合并策略说明 |
| 缓存复用机制详解 | 4.2 + 附录 A/B | 保留核心结构与示例 |
| 使用指南（重复两处） | 7 | 合并并结构化 |
| 安全与运维 / 安全与权限管理 / 部署与运维 | 5 + 6 | 归并分类 |
| 智能工具调用系统（两处） | 4.5 | 统一术语“工具编排” |

迁移建议：
- 若脚本/页面引用旧锚点，可添加跳转（可选）
- 旧文档保留 1 个版本周期后再归档
- 新增内容统一补充在本文件“附录”或对应章节

---
> 若需将本重构版回写为主文档，可在确认无遗漏后替换原 `RAG.md`，或通过 README 链接指向本文件。
