#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ä¸‹è½½å·¥å…· - é¢„å…ˆä¸‹è½½åµŒå…¥æ¨¡å‹ä»¥é¿å…é¦–æ¬¡è¿è¡Œæ—¶çš„ç­‰å¾…

è¯¥è„šæœ¬ç”¨äºé¢„ä¸‹è½½ Qwen/Qwen3-Embedding-0.6B åµŒå…¥æ¨¡å‹ï¼Œ
é¿å…åœ¨åº”ç”¨é¦–æ¬¡è¿è¡Œæ—¶è¿›è¡Œçº¦2GBçš„æ¨¡å‹ä¸‹è½½ã€‚

ä½¿ç”¨æ–¹æ³•:
    python download_model.py

ç‰¹æ€§:
- æ˜¾ç¤ºä¸‹è½½è¿›åº¦
- è‡ªåŠ¨åˆ›å»ºç¼“å­˜ç›®å½•
- æ¨¡å‹éªŒè¯æµ‹è¯•
- é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- Hugging Face tokenæ”¯æŒ
"""

import os
import sys
import time
import logging
from pathlib import Path
from dotenv import load_dotenv

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…tokenizerså¹¶è¡ŒåŒ–è­¦å‘Š
os.environ["TOKENIZERS_PARALLELISM"] = "false"

def load_hf_token_from_env():
    """ä» .env æ–‡ä»¶åŠ è½½ Hugging Face token"""
    # åŠ è½½ .env æ–‡ä»¶
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½äº† token
        if os.getenv('HUGGINGFACE_TOKEN'):
            logging.info("âœ… å·²ä» .env æ–‡ä»¶åŠ è½½ Hugging Face token")
        else:
            logging.warning("âš ï¸ .env æ–‡ä»¶ä¸­æœªæ‰¾åˆ° HUGGINGFACE_TOKEN")
    else:
        logging.warning("âš ï¸ æœªæ‰¾åˆ° .env æ–‡ä»¶")

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    try:
        import sentence_transformers
        import torch
        import numpy as np
        import huggingface_hub
        logging.info("âœ… æ‰€æœ‰å¿…è¦ä¾èµ–å·²å®‰è£…")
        return True
    except ImportError as e:
        logging.error(f"âŒ ç¼ºå°‘å¿…è¦ä¾èµ–: {e}")
        logging.error("è¯·å…ˆå®‰è£…ä¾èµ–: pip install sentence-transformers torch numpy huggingface_hub")
        return False

def check_and_setup_hf_token():
    """æ£€æŸ¥å’Œè®¾ç½®Hugging Face token"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„token
    hf_token = os.getenv('HUGGINGFACE_TOKEN') or os.getenv('HF_TOKEN')
    
    if hf_token:
        logging.info("âœ… æ£€æµ‹åˆ°Hugging Face token")
        # è®¾ç½®åˆ°huggingface_hubä½¿ç”¨çš„ç¯å¢ƒå˜é‡
        os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token
        return True
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»ç™»å½•
    try:
        from huggingface_hub import HfApi
        api = HfApi()
        user_info = api.whoami()
        if user_info:
            logging.info(f"âœ… å·²ç™»å½•Hugging Faceï¼Œç”¨æˆ·: {user_info.get('name', 'Unknown')}")
            return True
    except Exception:
        pass
    
    # æç¤ºç”¨æˆ·è®¾ç½®token
    logging.warning("âš ï¸ æœªæ£€æµ‹åˆ°Hugging Face token")
    logging.info("ğŸ’¡ è·å–tokençš„æ–¹æ³•:")
    logging.info("   1. è®¿é—®: https://huggingface.co/settings/tokens")
    logging.info("   2. åˆ›å»ºä¸€ä¸ªæ–°çš„token (Readæƒé™å³å¯)")
    logging.info("   3. è®¾ç½®ç¯å¢ƒå˜é‡: set HUGGINGFACE_TOKEN=your_token_here")
    logging.info("   4. æˆ–è€…è¿è¡Œ: huggingface-cli login")
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦è¾“å…¥token
    print("\né€‰æ‹©æ“ä½œ:")
    print("1. è¾“å…¥Hugging Face token")
    print("2. å°è¯•æ— tokenä¸‹è½½ (å¯èƒ½å¤±è´¥)")
    print("3. é€€å‡º")
    
    choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice == '1':
        token = input("è¯·è¾“å…¥æ‚¨çš„Hugging Face token: ").strip()
        if token:
            os.environ['HUGGINGFACE_HUB_TOKEN'] = token
            logging.info("âœ… Tokenå·²è®¾ç½®")
            return True
        else:
            logging.error("âŒ Tokenä¸èƒ½ä¸ºç©º")
            return False
    elif choice == '2':
        logging.warning("âš ï¸ å°†å°è¯•æ— tokenä¸‹è½½ï¼Œå¯èƒ½ä¼šå¤±è´¥")
        return True
    else:
        logging.info("ğŸ‘‹ ç”¨æˆ·é€‰æ‹©é€€å‡º")
        return False

def get_model_cache_dir():
    """è·å–æ¨¡å‹ç¼“å­˜ç›®å½•è·¯å¾„"""
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
    script_dir = Path(__file__).parent
    cache_dir = script_dir / "App" / "model_cache"
    return cache_dir

def download_embedding_model():
    """ä¸‹è½½åµŒå…¥æ¨¡å‹"""
    MODEL_NAME = 'Qwen/Qwen3-Embedding-0.6B'
    
    try:
        # å¯¼å…¥å¿…è¦çš„åº“
        from sentence_transformers import SentenceTransformer
        
        # è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•
        cache_dir = get_model_cache_dir()
        cache_dir.mkdir(parents=True, exist_ok=True)
        
        logging.info(f"ğŸ¯ å¼€å§‹ä¸‹è½½æ¨¡å‹: {MODEL_NAME}")
        logging.info(f"ğŸ“ ç¼“å­˜ç›®å½•: {cache_dir}")
        logging.info("â³ æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼ˆçº¦2GBï¼‰...")
        
        # æ£€æŸ¥Hugging Face tokenæ˜¯å¦æ­£ç¡®è®¾ç½®
        hf_token = os.getenv('HUGGINGFACE_TOKEN') or os.getenv('HUGGINGFACE_HUB_TOKEN')
        if hf_token:
            logging.info("ğŸ”‘ ä½¿ç”¨Hugging Face tokenè¿›è¡Œè®¤è¯")
        else:
            logging.warning("âš ï¸ æœªè®¾ç½®Hugging Face tokenï¼Œå¯èƒ½ä¼šé‡åˆ°è®¤è¯é—®é¢˜")
        
        start_time = time.time()
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆè¿™ä¼šè§¦å‘ä¸‹è½½ï¼‰
        model = SentenceTransformer(
            MODEL_NAME, 
            cache_folder=str(cache_dir),
            device='cpu',  # ä½¿ç”¨CPUé¿å…CUDAé—®é¢˜
            trust_remote_code=True  # ä¿¡ä»»è¿œç¨‹ä»£ç 
        )
        
        download_time = time.time() - start_time
        logging.info(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼è€—æ—¶: {download_time:.2f}ç§’")
        
        # è¿›è¡Œæµ‹è¯•ç¡®ä¿æ¨¡å‹å·¥ä½œæ­£å¸¸
        logging.info("ğŸ§ª æ­£åœ¨æµ‹è¯•æ¨¡å‹...")
        test_texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬", "æ¨¡å‹ä¸‹è½½æˆåŠŸ"]
        test_embeddings = model.encode(test_texts, show_progress_bar=False)
        
        logging.info(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼")
        logging.info(f"ğŸ“Š åµŒå…¥ç»´åº¦: {test_embeddings.shape}")
        logging.info(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {cache_dir}")
        
        # æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶ä¿¡æ¯
        show_model_info(cache_dir)
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        logging.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {error_msg}")
        
        # æä¾›é’ˆå¯¹æ€§çš„é”™è¯¯å»ºè®®
        if "401" in error_msg or "authentication" in error_msg.lower():
            logging.error("ğŸ”‘ è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥Hugging Face token")
            logging.error("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            logging.error("   1. ç¡®è®¤tokenæœ‰æ•ˆ")
            logging.error("   2. æ£€æŸ¥tokenæ˜¯å¦æœ‰è¯»å–æƒé™")
            logging.error("   3. å°è¯•é‡æ–°è¿è¡Œè„šæœ¬")
        elif "403" in error_msg or "forbidden" in error_msg.lower():
            logging.error("ğŸš« è®¿é—®è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦ç”³è¯·æ¨¡å‹è®¿é—®æƒé™")
            logging.error("ğŸ’¡ è¯·è®¿é—®æ¨¡å‹é¡µé¢ç”³è¯·è®¿é—®æƒé™: https://huggingface.co/Qwen/Qwen3-Embedding-0.6B")
        elif "timeout" in error_msg.lower() or "connection" in error_msg.lower():
            logging.error("ğŸŒ ç½‘ç»œè¿æ¥é—®é¢˜")
            logging.error("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            logging.error("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            logging.error("   2. ç¨åé‡è¯•")
            logging.error("   3. è€ƒè™‘ä½¿ç”¨VPN")
        elif "expecting value" in error_msg.lower() or "json" in error_msg.lower():
            logging.error("ğŸ“¡ JSONè§£æé”™è¯¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæˆ–æœåŠ¡å™¨é—®é¢˜")
            logging.error("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            logging.error("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
            logging.error("   2. ç¡®è®¤Hugging FaceæœåŠ¡æ˜¯å¦æ­£å¸¸")
            logging.error("   3. ç¨åé‡è¯•")
            logging.error("   4. è€ƒè™‘ä½¿ç”¨é•œåƒæºæˆ–VPN")
        else:
            logging.error("ğŸ’¡ é€šç”¨è§£å†³æ–¹æ¡ˆ:")
            logging.error("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            logging.error("   2. ç¡®è®¤Hugging Face token")
            logging.error("   3. é‡æ–°è¿è¡Œè„šæœ¬")
        
        return False

def show_model_info(cache_dir):
    """æ˜¾ç¤ºä¸‹è½½çš„æ¨¡å‹ä¿¡æ¯"""
    try:
        model_dir = cache_dir / "models--Qwen--Qwen3-Embedding-0.6B"
        if model_dir.exists():
            # è®¡ç®—æ¨¡å‹æ–‡ä»¶å¤§å°
            total_size = 0
            file_count = 0
            for root, dirs, files in os.walk(model_dir):
                for file in files:
                    file_path = Path(root) / file
                    if file_path.exists():
                        total_size += file_path.stat().st_size
                        file_count += 1
            
            # è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
            size_mb = total_size / (1024 * 1024)
            size_gb = size_mb / 1024
            
            logging.info("ğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
            logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {file_count}")
            if size_gb >= 1:
                logging.info(f"   ğŸ’¾ æ€»å¤§å°: {size_gb:.2f} GB")
            else:
                logging.info(f"   ğŸ’¾ æ€»å¤§å°: {size_mb:.2f} MB")
            logging.info(f"   ğŸ“ ä½ç½®: {model_dir}")
            
    except Exception as e:
        logging.warning(f"âš ï¸ è·å–æ¨¡å‹ä¿¡æ¯æ—¶å‡ºé”™: {e}")

def check_existing_model():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç»å­˜åœ¨"""
    cache_dir = get_model_cache_dir()
    model_dir = cache_dir / "models--Qwen--Qwen3-Embedding-0.6B"
    
    if model_dir.exists() and any(model_dir.iterdir()):
        logging.info("âœ… æ£€æµ‹åˆ°å·²å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶")
        show_model_info(cache_dir)
        return True
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ—…æ¸¸åŠ©æ‰‹ - æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 50)
    
    setup_logging()
    
    # åŠ è½½ Hugging Face token
    load_hf_token_from_env()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    # æ£€æŸ¥Hugging Face token
    if not check_and_setup_hf_token():
        sys.exit(1)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¨¡å‹
    if check_existing_model():
        choice = input("\nğŸ¤” æ¨¡å‹å·²å­˜åœ¨ï¼Œæ˜¯å¦é‡æ–°ä¸‹è½½ï¼Ÿ(y/N): ").strip().lower()
        if choice not in ['y', 'yes']:
            logging.info("â­ï¸ è·³è¿‡ä¸‹è½½ï¼Œä½¿ç”¨ç°æœ‰æ¨¡å‹")
            return
    
    # ä¸‹è½½æ¨¡å‹
    logging.info("ğŸ¬ å¼€å§‹ä¸‹è½½æµç¨‹...")
    success = download_embedding_model()
    
    if success:
        print("\n" + "=" * 50)
        print("ğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print("ğŸ’¡ æç¤ºï¼šç°åœ¨å¯ä»¥å¯åŠ¨åº”ç”¨ï¼Œå°†ä¸ä¼šå†æ¬¡ä¸‹è½½æ¨¡å‹")
        print("ğŸš€ è¿è¡Œåº”ç”¨: python App/app.py")
    else:
        print("\n" + "=" * 50)
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé”™è¯¯ä¿¡æ¯")
        sys.exit(1)

if __name__ == "__main__":
    main()